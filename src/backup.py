# src/backup.py
from __future__ import annotations

import os
import re
import sqlite3
import zipfile
from pathlib import Path
from datetime import datetime, timedelta

import discord

from utils.time_kst import now_kst
from repo.settings_repo import get_settings


# ê¸°ë³¸ê°’: ./data/backups
def _backup_dir() -> Path:
    p = os.environ.get("BACKUP_DIR", "./data/backups")
    d = Path(p)
    d.mkdir(parents=True, exist_ok=True)
    return d


def _marker_path() -> Path:
    return _backup_dir() / ".last_backup_date"


def _monthly_marker_path() -> Path:
    return _backup_dir() / ".last_monthly_archive_ym"

def _read_last_monthly_archive_ym() -> str:
    try:
        return _monthly_marker_path().read_text(encoding="utf-8").strip()
    except Exception:
        return ""

def _write_last_monthly_archive_ym(ym: str) -> None:
    try:
        _monthly_marker_path().write_text(ym, encoding="utf-8")
    except Exception:
        pass


def _read_last_backup_date() -> str:
    try:
        return _marker_path().read_text(encoding="utf-8").strip()
    except Exception:
        return ""


def _write_last_backup_date(date_text: str) -> None:
    try:
        _marker_path().write_text(date_text, encoding="utf-8")
    except Exception:
        pass


def _cleanup_old_backups(keep_days: int = 60) -> None:
    """
    ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬(ê¸°ë³¸ 60ì¼ ë³´ê´€).
    """
    d = _backup_dir()
    cutoff = now_kst().dt - timedelta(days=keep_days)

    for p in d.glob("inventory_backup_*.db"):
        m = re.search(r"inventory_backup_(\d{4}-\d{2}-\d{2})\.db$", p.name)
        if not m:
            continue
        try:
            dt = datetime.strptime(m.group(1), "%Y-%m-%d")
            if dt < cutoff.replace(tzinfo=None):
                p.unlink(missing_ok=True)
        except Exception:
            pass

    for p in d.glob("inventory_backup_*.zip"):
        m = re.search(r"inventory_backup_(\d{4}-\d{2}-\d{2})\.zip$", p.name)
        if not m:
            continue
        try:
            dt = datetime.strptime(m.group(1), "%Y-%m-%d")
            if dt < cutoff.replace(tzinfo=None):
                p.unlink(missing_ok=True)
        except Exception:
            pass


def _make_zip(db_path: Path) -> Path:
    zip_path = db_path.with_suffix(".zip")
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.write(db_path, arcname=db_path.name)
    return zip_path


async def _get_alert_channel(client, guild: discord.Guild):
    # alert_channel_id ë˜ëŠ” report_channel_idë¡œ ì•Œë¦¼ ë³´ëƒ„
    s = get_settings(client.conn, guild.id)
    ch_id = s.get("alert_channel_id") or s.get("report_channel_id")
    if not ch_id:
        return None
    ch = guild.get_channel(int(ch_id))
    return ch if isinstance(ch, discord.TextChannel) else None


def do_backup_sqlite(src_conn: sqlite3.Connection, target_path: Path) -> None:
    """
    sqlite3 ë°±ì—… APIë¡œ ì•ˆì „í•˜ê²Œ ìŠ¤ëƒ…ìƒ· ìƒì„±.
    """
    # í˜¹ì‹œ ëª¨ë¥¼ flush
    try:
        src_conn.commit()
    except Exception:
        pass

    dst_conn = sqlite3.connect(str(target_path))
    try:
        src_conn.backup(dst_conn)  # ì˜¨ë¼ì¸ ë°±ì—…
        dst_conn.commit()
    finally:
        dst_conn.close()


async def run_daily_backup(client, guild: discord.Guild, hour: int = 18, minute: int = 40) -> None:
    """
    âœ… ë§¤ì¼ (ê¸°ë³¸ 18:40 KST) DB ë°±ì—… ì‹¤í–‰
    - 18:30 ë¦¬í¬íŠ¸ í›„ 10ë¶„ ë’¤ë¡œ ê¸°ë³¸ ì„¤ì •
    - í•˜ë£¨ 1ë²ˆë§Œ ìˆ˜í–‰(.last_backup_dateë¡œ ì¤‘ë³µ ë°©ì§€)
    """
    k = now_kst()
    dt = k.dt
    today = dt.strftime("%Y-%m-%d")

    scheduled = dt.replace(hour=hour, minute=minute, second=0, microsecond=0)
    if dt < scheduled:
        return

    if _read_last_backup_date() == today:
        return

    d = _backup_dir()
    db_file = d / f"inventory_backup_{today}.db"

    do_backup_sqlite(client.conn, db_file)

    # ì •ë¦¬
    _cleanup_old_backups(keep_days=60)

    # ì•Œë¦¼ ì±„ë„ì— ê²°ê³¼ë§Œ ë‚¨ê¸°ê¸°(íŒŒì¼ ì—…ë¡œë“œëŠ” ìš©ëŸ‰ ì•ˆì „í•  ë•Œë§Œ)
    ch = await _get_alert_channel(client, guild)
    if ch:
        size = db_file.stat().st_size
        size_mb = size / (1024 * 1024)

        # ë””ìŠ¤ì½”ë“œ ê¸°ë³¸ ì—…ë¡œë“œ ì œí•œ(ì•ˆì „í•˜ê²Œ 8MB ê¸°ì¤€)
        MAX_UPLOAD = 8 * 1024 * 1024

        # zip ë§Œë“¤ì–´ì„œ ë” ì‘ì•„ì§€ë©´ ì˜¬ë¦¬ê¸° ì‹œë„
        zip_path = _make_zip(db_file)
        zip_size = zip_path.stat().st_size

        if zip_size <= MAX_UPLOAD:
            await ch.send(
                content=f"ğŸ—„ï¸ DB ë°±ì—… ì™„ë£Œ ({today})",
                file=discord.File(fp=str(zip_path), filename=zip_path.name),
            )
        else:
            await ch.send(
                f"ğŸ—„ï¸ DB ë°±ì—… ì™„ë£Œ ({today})\n"
                f"- íŒŒì¼: `{db_file.name}` ({size_mb:.2f}MB)\n"
                f"- zipì´ 8MBë¥¼ ì´ˆê³¼í•´ì„œ ì±„ë„ ì—…ë¡œë“œëŠ” ìƒëµí–ˆì–´ìš”. (ì„œë²„ì— ì €ì¥ë¨)"
            )

    _write_last_backup_date(today)


async def force_backup_now(client, guild: discord.Guild) -> tuple[bool, str]:
    """
    âœ… ê´€ë¦¬ì ìˆ˜ë™ ë°±ì—…: ì§€ê¸ˆ ì¦‰ì‹œ ë°±ì—… ìƒì„± + (ê°€ëŠ¥í•˜ë©´) ì—…ë¡œë“œ
    """
    k = now_kst()
    dt = k.dt
    today = dt.strftime("%Y-%m-%d")

    d = _backup_dir()
    db_file = d / f"inventory_backup_{today}.db"

    do_backup_sqlite(client.conn, db_file)
    _cleanup_old_backups(keep_days=60)

    ch = await _get_alert_channel(client, guild)
    if not ch:
        return False, "ë¦¬í¬íŠ¸/ì•Œë¦¼ ì±„ë„ì´ ë¯¸ì„¤ì •ì´ë¼ ì—…ë¡œë“œëŠ” ëª» í–ˆì–´ìš”. ì„œë²„ì— ë°±ì—… íŒŒì¼ì€ ì €ì¥ëì–´ìš”."

    MAX_UPLOAD = 8 * 1024 * 1024
    zip_path = _make_zip(db_file)

    if zip_path.stat().st_size <= MAX_UPLOAD:
        await ch.send(
            content=f"ğŸ—„ï¸ (ìˆ˜ë™) DB ë°±ì—… ì™„ë£Œ ({today})",
            file=discord.File(fp=str(zip_path), filename=zip_path.name),
        )
        return True, "ì±„ë„ ì—…ë¡œë“œê¹Œì§€ ì™„ë£Œí–ˆì–´ìš”."
    else:
        size_mb = db_file.stat().st_size / (1024 * 1024)
        await ch.send(
            f"ğŸ—„ï¸ (ìˆ˜ë™) DB ë°±ì—… ì™„ë£Œ ({today})\n"
            f"- íŒŒì¼: `{db_file.name}` ({size_mb:.2f}MB)\n"
            f"- zipì´ 8MBë¥¼ ì´ˆê³¼í•´ì„œ ì±„ë„ ì—…ë¡œë“œëŠ” ìƒëµí–ˆì–´ìš”. (ì„œë²„ì— ì €ì¥ë¨)"
        )
        return True, "ë°±ì—…ì€ í–ˆê³ , ìš©ëŸ‰ ë•Œë¬¸ì— ì±„ë„ ì—…ë¡œë“œëŠ” ìƒëµëì–´ìš”."


def list_backup_files(limit: int = 20) -> list[tuple[str, float, float]]:
    """
    returns [(filename, size_mb, mtime_epoch), ...] newest first
    """
    d = _backup_dir()
    files = []
    for p in d.glob("inventory_backup_*"):
        if p.is_file():
            size_mb = p.stat().st_size / (1024 * 1024)
            files.append((p.name, size_mb, p.stat().st_mtime))
    files.sort(key=lambda x: x[2], reverse=True)
    return files[:max(1, min(limit, 50))]


async def run_monthly_archive(client, guild: discord.Guild, hour: int = 18, minute: int = 50) -> None:
    """
    âœ… ë§¤ë‹¬ 1ì¼ (ê¸°ë³¸ 18:50 KST) ì— 'ì§€ë‚œë‹¬ ë°±ì—…ë“¤'ì„ ZIPë¡œ ë¬¶ì–´ ì—…ë¡œë“œ ì‹œë„
    - 1ì¼ë¡œ í•˜ëŠ” ì´ìœ : ì›”ë§ì— ì„œë²„ê°€ êº¼ì ¸ë„ ë‹¤ìŒë‚ (1ì¼) ì‚´ì•„ë‚˜ë©´ ì²˜ë¦¬ ê°€ëŠ¥
    - ì¤‘ë³µ ì—…ë¡œë“œ ë°©ì§€: .last_monthly_archive_ym
    """
    k = now_kst()
    dt = k.dt

    # ë§¤ë‹¬ 1ì¼ë§Œ
    if dt.day != 1:
        return

    scheduled = dt.replace(hour=hour, minute=minute, second=0, microsecond=0)
    if dt < scheduled:
        return

    # ì§€ë‚œë‹¬
    prev_month_dt = (dt.replace(day=1) - timedelta(days=1))
    ym = prev_month_dt.strftime("%Y-%m")

    if _read_last_monthly_archive_ym() == ym:
        return

    d = _backup_dir()

    # ì§€ë‚œë‹¬ì˜ ì¼ì¼ ë°±ì—…(.db)ë§Œ ëª¨ì•„ì„œ zip ë§Œë“¤ê¸°
    # íŒŒì¼ëª…: inventory_backup_YYYY-MM-DD.db
    prefix = f"inventory_backup_{ym}-"  # ì˜ˆ: inventory_backup_2026-01-
    db_files = sorted([p for p in d.glob(f"{prefix}*.db") if p.is_file()])

    # ì—†ìœ¼ë©´ ì¢…ë£Œ(ì•„ì§ ë°±ì—…ì´ ì—†ê±°ë‚˜ íŒŒì¼ ê·œì¹™ ë³€ê²½ ë“±)
    if not db_files:
        ch = await _get_alert_channel(client, guild)
        if ch:
            await ch.send(f"ğŸ“¦ ì›”ê°„ ë°±ì—… ZIP ìƒì„± ì‹œë„({ym}) â†’ í•´ë‹¹ ì›”ì˜ ì¼ì¼ ë°±ì—… íŒŒì¼ì´ ì—†ì–´ì„œ ê±´ë„ˆë›°ì—ˆì–´ìš”.")
        _write_last_monthly_archive_ym(ym)
        return

    zip_path = d / f"inventory_backup_{ym}.zip"
    try:
        with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            for p in db_files:
                zf.write(p, arcname=p.name)
    except Exception:
        # zip ìƒì„± ì‹¤íŒ¨
        ch = await _get_alert_channel(client, guild)
        if ch:
            await ch.send(f"ğŸ“¦ ì›”ê°„ ë°±ì—… ZIP ìƒì„± ì‹¤íŒ¨({ym})")
        return

    # ì—…ë¡œë“œ ì‹œë„(8MB ê¸°ì¤€)
    ch = await _get_alert_channel(client, guild)
    if ch:
        MAX_UPLOAD = 8 * 1024 * 1024
        zsize = zip_path.stat().st_size
        zmb = zsize / (1024 * 1024)

        if zsize <= MAX_UPLOAD:
            await ch.send(
                content=f"ğŸ“¦ ì›”ê°„ DB ë°±ì—… ZIP ({ym})",
                file=discord.File(fp=str(zip_path), filename=zip_path.name),
            )
        else:
            await ch.send(
                f"ğŸ“¦ ì›”ê°„ DB ë°±ì—… ZIP ìƒì„± ì™„ë£Œ({ym})\n"
                f"- íŒŒì¼: `{zip_path.name}` ({zmb:.2f}MB)\n"
                f"- 8MB ì´ˆê³¼ë¡œ ì±„ë„ ì—…ë¡œë“œëŠ” ìƒëµí–ˆì–´ìš”. (ì„œë²„ì— ì €ì¥ë¨)"
            )

    _write_last_monthly_archive_ym(ym)
